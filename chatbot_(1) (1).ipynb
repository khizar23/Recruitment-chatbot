{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1fe90751",
      "metadata": {
        "id": "1fe90751"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "import random\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from datetime import datetime, date\n",
        "import tensorflow as tf\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "277d6f9a",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "277d6f9a",
        "outputId": "91d232cd-e212-40bc-a2eb-a3bbea61f3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hello, thanks for visiting', 'Good to see you again', 'Hi there, how can I help?'], 'context_set': ''}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'hours', 'patterns': ['What hours are you open?', 'What are your hours?', 'When are you open?'], 'responses': [\"We're open every day 9am-9pm\", 'Our hours are 9am-9pm every day']}, {'tag': 'name', 'patterns': ['My name is', 'You can call me', 'Everyone calls me'], 'responses': ['Can you please tell me more about you?', 'Describe yourself']}]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Opening JSON file\n",
        "f = open('/content/intent.json',)\n",
        "\n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ac0d530d",
      "metadata": {
        "id": "ac0d530d"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1a5d8fc4",
      "metadata": {
        "id": "1a5d8fc4"
      },
      "outputs": [],
      "source": [
        "stop_words = ['is','am','the','a','an','be','are','were',]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r9Vy6WNPQso",
        "outputId": "846e01db-3b85-4a41-ba18-cc317bd17812"
      },
      "id": "-r9Vy6WNPQso",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4a310647",
      "metadata": {
        "id": "4a310647"
      },
      "outputs": [],
      "source": [
        "\n",
        "words = []\n",
        "y = []\n",
        "patterns =[]\n",
        "x = []\n",
        "classes = []\n",
        "# getting the classes(tags) output and patterns from 'data'\n",
        "for intent in data['intents']:\n",
        "    classes.append(intent['tag'])\n",
        "    for pattern in intent['patterns']:\n",
        "# applying tokenizer to convert the sentences into a list of words\n",
        "        tokens = nltk.word_tokenize(pattern)\n",
        "# here .extend() is used instead of append() since we don't want to append lists in words\n",
        "# but its elements i.e words in 'token'\n",
        "# here 'tokens' is a list of words\n",
        "        words.extend(tokens)\n",
        "        patterns.append(pattern)\n",
        "        y.append(intent['tag'])\n",
        "\n",
        "# converting to lower case, applyging lemmatization removing the puctuations\n",
        "# here 'words' is our vocabulary containing all the words\n",
        "words = [stemmer.stem(word.lower()) for word  in words if word not in string.punctuation and\n",
        "        word not in stop_words]\n",
        "# converting the list to set to avoid doubling of words in in 'words'\n",
        "words = sorted(set(words))\n",
        "words = list(words)\n",
        "\n",
        "for list_ in patterns:\n",
        "    list_ = nltk.word_tokenize(list_)\n",
        "    list_ = [stemmer.stem(lis.lower()) for lis in list_ if lis not in string.punctuation and lis not in stop_words]\n",
        "    x.append(list_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9d469952",
      "metadata": {
        "id": "9d469952"
      },
      "outputs": [],
      "source": [
        "# applying the one hot encoding on our training data\n",
        "train_x = []\n",
        "train_y = []\n",
        "training = []\n",
        "empty_list = [0]*len(classes)\n",
        "for idx,list_ in enumerate(x):\n",
        "    doc = []\n",
        "    for word in words:\n",
        "        doc.append(1) if word in list_ else doc.append(0)\n",
        "    output = list(empty_list)\n",
        "    output[classes.index(y[idx])] = 1\n",
        "    training.append([doc,output])\n",
        "random.shuffle(training)\n",
        "training = np.array(training,dtype = object)\n",
        "train_x = list(training[:,0])\n",
        "train_x = np.array(train_x)\n",
        "train_y = np.array(list(training[:,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "815983cd",
      "metadata": {
        "id": "815983cd"
      },
      "outputs": [],
      "source": [
        "ACCURACY_THRESHOLD = 0.99\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy') > ACCURACY_THRESHOLD):\n",
        "            print(\"\\nTraining stopped at epoch number:\",epoch)\n",
        "            self.model.stop_training = True\n",
        "callbacks = myCallback()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "473f70a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "473f70a7",
        "outputId": "0b5866ff-593d-442c-dade-b8deeda11342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 1.6771 - accuracy: 0.1765\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5246 - accuracy: 0.4118\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3107 - accuracy: 0.6471\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3532 - accuracy: 0.5294\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1735 - accuracy: 0.8235\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0837 - accuracy: 0.6471\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9786 - accuracy: 0.7059\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8685 - accuracy: 0.8235\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7805 - accuracy: 0.9412\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.9412\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 1.0000\n",
            "Training stopped at epoch number: 10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78165089dfc0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "input_shape = (len(train_x[1]),)\n",
        "output_shape = len(train_y[0])\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(output_shape, activation = \"softmax\"))\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x=train_x, y=train_y, epochs=200, verbose=1,callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7b8ac102",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b8ac102",
        "outputId": "29b7a4cd-d462-4177-fc97-ce69881e3271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as: chatbot_model.sav\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the Random Forest model to a file\n",
        "model_filename = \"chatbot_model.sav\"\n",
        "pickle.dump(model, open(model_filename,'wb'))\n",
        "\n",
        "print(\"Model saved as:\", model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fd1c4f6",
      "metadata": {
        "id": "0fd1c4f6"
      },
      "outputs": [],
      "source": [
        "# applying bag of words techniques to convert user's text in binary\n",
        "def bagofwords(msg):\n",
        "    tokens = nltk.word_tokenize(msg)\n",
        "    tokens = [stemmer.stem(token.lower()) for token in tokens if token not in string.punctuation and token\n",
        "              not in stop_words]\n",
        "    binary_msg = []\n",
        "    for word in words:\n",
        "        binary_msg.append(1) if word in tokens else binary_msg.append(0)\n",
        "    return np.array(binary_msg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a869fb5",
      "metadata": {
        "id": "0a869fb5"
      },
      "outputs": [],
      "source": [
        "def prediction(msg):\n",
        "\n",
        "    message = bagofwords(msg)\n",
        "    result = model.predict(np.array([message]))\n",
        "    result = np.argmax(result,axis=1)\n",
        "    class_index = list(result)[0]\n",
        "    current_tag = classes[class_index]\n",
        "\n",
        "\n",
        "    for intent in data['intents']:\n",
        "        if intent['tag'] == current_tag:\n",
        "            response = random.choice(intent['responses'])\n",
        "            return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d2b1ca",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "99d2b1ca",
        "outputId": "ab9f7c21-8663-4e6c-e0de-4dced3753546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "Hello, thanks for visiting\n",
            "name\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Describe yourself\n",
            "goodbye\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "See you later, thanks for visiting\n",
            "thanks\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Happy to help!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-97ac9dbc5a09>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "text = input()\n",
        "response = prediction(text)\n",
        "while True:\n",
        "    print(response)\n",
        "    text = input()\n",
        "    response = prediction(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe457aa",
      "metadata": {
        "id": "efe457aa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}